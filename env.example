# ========================================
# Metadata Builder Environment Configuration
# ========================================
# Copy this file to .env and fill in your actual values
# Never commit .env to version control!

# ========================================
# LLM Provider Configuration
# ========================================

# OpenRouter (Recommended - gives access to multiple models)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
# Other model options:
# anthropic/claude-3-opus
# openai/gpt-4-turbo-preview
# openai/gpt-3.5-turbo
# google/gemini-pro
# mistral/mistral-large

# Alternative LLM Providers (uncomment to use instead of OpenRouter)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=gpt-4-turbo-preview

# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_BASE_URL=https://api.anthropic.com
# ANTHROPIC_MODEL=claude-3-opus-20240229

# ========================================
# Database Configuration
# ========================================

# Primary database connection
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/postgres
DEFAULT_DATABASE=postgres

# User Management Schema Configuration  
AUTH_SCHEMA=metadata_builder

# Database connection pool settings
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# ========================================
# API Server Configuration
# ========================================

API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_TIMEOUT=300

# CORS settings
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# ========================================
# Frontend Configuration
# ========================================

REACT_APP_API_URL=http://localhost:8000
REACT_APP_ENVIRONMENT=development

# ========================================
# Logging Configuration
# ========================================

LOG_LEVEL=INFO
LOG_FILE=logs/metadata_builder.log
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_ROTATION=midnight
LOG_BACKUP_COUNT=7

# ========================================
# Security Configuration
# ========================================

# Generate a secure secret key for your deployment
SECRET_KEY=your-super-secret-key-change-this-in-production
JWT_SECRET_KEY=your-jwt-secret-key-here
JWT_EXPIRATION_HOURS=24

# Session credential encryption key (32-byte key for Fernet encryption)
SESSION_ENCRYPTION_KEY=your-32-byte-encryption-key-here

# Access token settings
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# ========================================
# Rate Limiting
# ========================================

RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600
RATE_LIMIT_STORAGE=memory

# ========================================
# Background Jobs (Optional)
# ========================================

# Redis configuration for background jobs
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Job timeout settings
METADATA_GENERATION_TIMEOUT=600
LOOKML_GENERATION_TIMEOUT=300

# ========================================
# Development Settings
# ========================================

DEBUG=true
ENVIRONMENT=development
TESTING=false

# Enable/disable features
ENABLE_AGENT_CHAT=true
ENABLE_MCP_SERVER=true
ENABLE_BACKGROUND_JOBS=false

# ========================================
# Monitoring & Analytics (Optional)
# ========================================

# Application monitoring
SENTRY_DSN=your_sentry_dsn_here
ENABLE_METRICS=false

# Usage analytics
ENABLE_ANALYTICS=false
ANALYTICS_ENDPOINT=https://analytics.example.com

# ========================================
# Cache Configuration
# ========================================

CACHE_TYPE=simple
CACHE_DEFAULT_TIMEOUT=300
CACHE_REDIS_URL=redis://localhost:6379/1

# ========================================
# MCP Server Configuration
# ========================================

MCP_SERVER_PORT=8001
MCP_SERVER_HOST=0.0.0.0
MCP_ENABLE_FASTMCP=false  # Set to true if you have Python 3.10+

# ========================================
# BigQuery Configuration (If using BigQuery)
# ========================================

# GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account.json
# BIGQUERY_PROJECT_ID=your-project-id
# BIGQUERY_DATASET=your-dataset
# BIGQUERY_LOCATION=US

# ========================================
# Advanced Configuration
# ========================================

# Token limits for LLM calls
MAX_TOKENS_PER_REQUEST=8000
MAX_CONTEXT_LENGTH=32000

# Metadata generation settings
DEFAULT_SAMPLE_SIZE=1000
DEFAULT_NUM_SAMPLES=5
MAX_PARTITIONS=10

# Semantic model generation
ENABLE_SEMANTIC_MODELS=true
LOOKML_OUTPUT_FORMAT=yaml 